{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikit-learn version 1.5.1 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
      "Torch version 2.3.1 has not been tested with coremltools. You may run into unexpected errors. Torch 2.2.0 is the most recent version that has been tested.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import coremltools as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperPointNet(torch.nn.Module):\n",
    "  \"\"\" Pytorch definition of SuperPoint Network. \"\"\"\n",
    "  def __init__(self):\n",
    "    super(SuperPointNet, self).__init__()\n",
    "    self.relu = torch.nn.ReLU(inplace=True)\n",
    "    self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Shared Encoder.\n",
    "    self.conv1a = torch.nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv1b = torch.nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv2a = torch.nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv2b = torch.nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv3a = torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv3b = torch.nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv4a = torch.nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv4b = torch.nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "    # Detector Head.\n",
    "    self.convPa = torch.nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "    self.convPb = torch.nn.Conv2d(256, 65, kernel_size=1, stride=1, padding=0)\n",
    "    # Descriptor Head.\n",
    "    self.convDa = torch.nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "    self.convDb = torch.nn.Conv2d(256, 256, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\" Forward pass that jointly computes unprocessed point and descriptor\n",
    "    tensors.\n",
    "    Input\n",
    "      x: Image pytorch tensor shaped N x 1 x H x W.\n",
    "    Output\n",
    "      semi: Output point pytorch tensor shaped N x 65 x H/8 x W/8.\n",
    "      desc: Output descriptor pytorch tensor shaped N x 256 x H/8 x W/8.\n",
    "    \"\"\"\n",
    "    # Shared Encoder.\n",
    "    x = self.relu(self.conv1a(x))\n",
    "    x = self.relu(self.conv1b(x))\n",
    "    x = self.pool(x)\n",
    "    x = self.relu(self.conv2a(x))\n",
    "    x = self.relu(self.conv2b(x))\n",
    "    x = self.pool(x)\n",
    "    x = self.relu(self.conv3a(x))\n",
    "    x = self.relu(self.conv3b(x))\n",
    "    x = self.pool(x)\n",
    "    x = self.relu(self.conv4a(x))\n",
    "    x = self.relu(self.conv4b(x))\n",
    "    # Detector Head.\n",
    "    cPa = self.relu(self.convPa(x))\n",
    "    semi = self.convPb(cPa)\n",
    "    # Descriptor Head.\n",
    "    cDa = self.relu(self.convDa(x))\n",
    "    desc = self.convDb(cDa)\n",
    "    dn = torch.norm(desc, p=2, dim=1) # Compute the norm.\n",
    "    desc = desc.div(torch.unsqueeze(dn, 1)) # Divide by norm to normalize.\n",
    "    return semi, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SuperPointNet()\n",
    "model.load_state_dict(torch.load('models/superpoint_v1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model is not in eval mode. Consider calling '.eval()' on your model prior to conversion\n",
      "Tuple detected at graph output. This will be flattened in the converted model.\n",
      "Converting PyTorch Frontend ==> MIL Ops:  99%|█████████▊| 153/155 [00:00<00:00, 9181.98 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|██████████| 5/5 [00:00<00:00, 844.13 passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 78/78 [00:00<00:00, 445.13 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 878.48 passes/s]\n"
     ]
    }
   ],
   "source": [
    "# script model with input of width 240, height 320\n",
    "scripted = torch.jit.trace(model, torch.rand(1, 1, 240, 320))\n",
    "\n",
    "\n",
    "# Convert the PyTorch model to CoreML format\n",
    "coreml_model = ct.convert(\n",
    "    scripted,\n",
    "    convert_to='mlprogram',\n",
    "    inputs=[ct.ImageType(name=\"image\", shape=(1, 1, 240, 320), color_layout=ct.colorlayout.GRAYSCALE)],\n",
    "    outputs=[ct.TensorType(name=\"semi\"), ct.TensorType(name=\"desc\")]\n",
    ")\n",
    "coreml_model.save(\"superpoint.mlpackage\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
